{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dbe083-0c09-4a77-a364-c6991c5b6dae",
   "metadata": {},
   "source": [
    "# Exercise: (Dense) Matrix-Matrix Multiplication\n",
    "\n",
    "In this exercise you will consider dense matrix-matrix multiplication\n",
    "\n",
    "$C_{rc} = \\sum_{k=1}^{n} A_{rk} B_{kc}$\n",
    "\n",
    "for square matrices $A$, $B$, and $C$ of size $n \\times n$. Despite being seemingly simple, you will see that different implementations have vastly different performance.\n",
    "\n",
    "## Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56035a1-a5f8-4299-8d61-208efeaa8c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading packages\n",
    "using BenchmarkTools\n",
    "using CpuId\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "BLAS.set_num_threads(1)\n",
    "\n",
    "# input (not to be modified)\n",
    "const N = 2048\n",
    "const C = zeros(N, N)\n",
    "const A = rand(N, N)\n",
    "const B = rand(N, N);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c7947-a4ac-4240-a537-aff4301fe27c",
   "metadata": {},
   "source": [
    "1) Benchmark the naive implementation `matmul_naive!` below in GFLOPS (giga floating-point operations per second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24348c5b-c826-4220-8e8a-dee20f474314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_naive! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matmul_naive!(C, A, B)\n",
    "    @assert size(C) == size(A) == size(B)\n",
    "    @assert size(C, 1) == size(C, 2)\n",
    "    n = size(C, 1)\n",
    "    fill!(C, zero(eltype(C)))\n",
    "\n",
    "    # - c: for columns of B and C\n",
    "    # - r: for rows    of A and C\n",
    "    # - k: for columns of A and rows of B\n",
    "    for c in 1:n\n",
    "        for r in 1:n\n",
    "            c_reg = 0.0\n",
    "            for k in 1:n\n",
    "                @inbounds c_reg += A[r, k] * B[k, c]\n",
    "            end\n",
    "            @inbounds C[r, c] = c_reg\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2865ce0-02de-4575-ac83-426f849ba7c2",
   "metadata": {},
   "source": [
    "**Note: The test and benchmark below can take while (~ 5 min). You might want to start with task 3 in the meantime.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51ae68-0dc2-4fc6-92ac-28283bc4d228",
   "metadata": {},
   "source": [
    "Correctness check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71b1bf1-382c-4fab-8ebc-54830f1233bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test matmul_naive!(C, A, B) ≈ mul!(C, A, B) # can take a while"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e569d2-e501-49a2-b077-071306dc904b",
   "metadata": {},
   "source": [
    "Benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e527f9-5dca-4ce8-ad03-399fe10d4c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_naive!: 104.8520426585 sec, performance = 0.16 GFLOP/s\n"
     ]
    }
   ],
   "source": [
    "t_naive = @belapsed matmul_naive!($C, $A, $B) samples = 1 evals = 2\n",
    "println(\"matmul_naive!: \", t_naive, \" sec, performance = \", round(2.0e-9 * N^3 / t_naive, digits=2), \" GFLOP/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47fde8a-28bf-45a7-b3ca-3ee63b4be3d3",
   "metadata": {},
   "source": [
    "2) Why is `matmul_naive!` so (super) slow?\n",
    "    * Hints: Look at the memory access pattern of innermost loop.\n",
    "\n",
    "**Answer:** Strided memory access for `A` in `matmul_naive!` reduces the performance. The implementation doesn't take column-major order into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc8fed-c2dd-4993-a8d6-241650bc7a44",
   "metadata": {},
   "source": [
    "3) Implement an improved version with contiguous memory access (better spatial locality) in `matmul_contiguous!` and benchmark it. How much faster is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8a5bc1-bc5b-4f72-9c5a-0eed49c54f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_contiguous! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matmul_contiguous!(C, A, B)\n",
    "    @assert size(C) == size(A) == size(B)\n",
    "    @assert size(C, 1) == size(C, 2)\n",
    "    n = size(C, 1)\n",
    "    fill!(C, zero(eltype(C)))\n",
    "\n",
    "    # - c: for columns of B and C\n",
    "    # - r: for rows    of A and C\n",
    "    # - k: for columns of A and rows of B\n",
    "    \n",
    "    #\n",
    "    # TODO: Implement improved version with more efficient memory access / better localitly.\n",
    "    #       Hint: Which loop should be the innermost?\n",
    "    #\n",
    "    for c in 1:n\n",
    "        for k in 1:n\n",
    "            @inbounds b = B[k, c]\n",
    "            for r in 1:n\n",
    "                @inbounds C[r, c] += A[r, k] * b\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5be3f-047e-4b70-8c23-4eb65f12a6d0",
   "metadata": {},
   "source": [
    "Correctness check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d0cb45-4b36-4949-82ee-586e86c42204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test matmul_contiguous!(C, A, B) ≈ mul!(C, A, B) # this should give true, otherwise your implementation is incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4da8c-c1e0-4280-a340-d08e4f041c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "Benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f6cc29-e742-4b40-a38f-4d9c705522de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_contiguous!: 1.5833908785 sec, performance = 10.85 GFLOP/s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# TODO: Benchmark like matmul_naive! above\n",
    "#\n",
    "t_contiguous = @belapsed matmul_contiguous!($C, $A, $B) samples = 1 evals = 2\n",
    "println(\"matmul_contiguous!: \", t_contiguous, \" sec, performance = \", round(2.0e-9 * N^3 / t_contiguous, digits=2), \" GFLOP/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066927e-1958-4c53-a386-31f628cd015a",
   "metadata": {},
   "source": [
    "### Cache Blocking\n",
    "\n",
    "The key idea of cache blocking is to perform the overall matrix-matrix multiplication in terms of smaller matrix-matrix multiplications of sub-blocks.\n",
    "\n",
    "<img src=\"../imgs/dMMM_cache_blocking.png\" width=800>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124c1234-ee8a-4d2a-90ae-977374b3ded7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matmul_cache_blocking! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function matmul_cache_blocking!(C, A, B; col_blksize=16, row_blksize=128, k_blksize=16)\n",
    "    @assert size(C) == size(A) == size(B)\n",
    "    @assert size(C, 1) == size(C, 2)\n",
    "    n = size(C, 1)\n",
    "    fill!(C, zero(eltype(C)))\n",
    "\n",
    "    # - c: for columns of B and C\n",
    "    # - r: for rows    of A and C\n",
    "    # - k: for columns of A and rows of B\n",
    "    for ic in 1:col_blksize:n\n",
    "        for ir in 1:row_blksize:n\n",
    "            for ik in 1:k_blksize:n\n",
    "                #\n",
    "                # begin: cache blocking\n",
    "                #\n",
    "                for jc in ic:min(ic + col_blksize - 1, n)\n",
    "                    for jk in ik:min(ik + k_blksize - 1, n)\n",
    "                        @inbounds b = B[jk, jc]\n",
    "                        for jr in ir:min(ir + row_blksize - 1, n)\n",
    "                            @inbounds C[jr, jc] += A[jr, jk] * b\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "                #\n",
    "                # end: cache blocking\n",
    "                #\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738042b4-3c53-4907-b93c-4dd943886e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test matmul_cache_blocking!(C, A, B) ≈ mul!(C, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a054cc-9667-43d5-8101-309e20cf010e",
   "metadata": {},
   "source": [
    "4) Inspect the given variant `matmul_cache_blocking!` which implements cache blocking.\n",
    "    * In which limit, that is, for what block size values, does the code semantically reduce to your code in 3)?\n",
    "    * Staying away from these limits, how can this implementation be faster?\n",
    "    \n",
    "**Answer:**\n",
    "* For `c_blksize = r_blksize = k_blksize = 1` and `c_blksize = r_blksize = k_blksize = n`.\n",
    "* By operating on blocks that, ideally, fit into L1 or L2 cache, we maximize fast data reuse (temporal locality).\n",
    "\n",
    "5) Benchmark the cache blocking variant. Specifically, we consider `c_blksize = 16`, `r_blksize = 128` and `k_blksize = 16` for the block sizes (default values).\n",
    "    * Can you give an argument why it makes sense to choose `r_blksize` larger than the others?\n",
    "    * How big (in bytes) are the blocks for `A` and `C` for these values? How does this compare to the L1 cache size of 32 KiB?\n",
    "    \n",
    "**Answer:**\n",
    "* Julia arrays are column-major order which aligns with the row index `r`.\n",
    "* Both blocks (`r_blksize * k_blksize` for A and `r_blksize * c_blksize` for C) are 16 * 128 * 8 bytes = 16 KiB big. Hence, they fit into L1 cache together.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687a0259-19bb-4a2b-babe-1c71b5dce954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_cache_blocking!: 1.2180994245 sec, performance = 14.1 GFLOP/s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# TODO: Benchmark matmul_cache_blocking! like above\n",
    "#\n",
    "t_cache_blocking = @belapsed matmul_cache_blocking!($C, $A, $B) samples = 1 evals = 2\n",
    "println(\"matmul_cache_blocking!: \", t_cache_blocking, \" sec, performance = \", round(2.0e-9 * N^3 / t_cache_blocking, digits=2), \" GFLOP/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e6eb4-6ef5-4ea5-920c-a058fd0e7705",
   "metadata": {},
   "source": [
    "6) Compare the performance of the cache-blocking variant to the built-in BLAS matrix multiply, i.e. `mul!(C, A, B)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa123214-113e-4e66-b268-a82dc5790fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul! (BLAS): 0.3555526105 sec, performance = 48.32 GFLOP/s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# TODO: Benchmark mul! like above\n",
    "#\n",
    "t_BLAS = @belapsed mul!($C, $A, $B) samples = 1 evals = 2\n",
    "println(\"mul! (BLAS): \", t_BLAS, \" sec, performance = \", round(2.0e-9 * N^3 / t_BLAS, digits=2), \" GFLOP/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a9663-60d3-4a1f-9ebb-048815eca436",
   "metadata": {},
   "source": [
    "7) **Bonus task:** vary the block sizes (in powers of 2) and see how the performance changes. (**This might take > 15 minutes.**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6008dcd3-70a0-4be6-b189-1b6216dbf2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varying block sizes:\n",
      "matmul_cache_block (4, 4, 4): 11.3368997755 sec, performance = 1.52 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 128, 4): 1.4426591985 sec, performance = 11.91 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 256, 4): 1.245917606 sec, performance = 13.79 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 512, 4): 1.156393876 sec, performance = 14.86 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 4, 8): 10.835570491 sec, performance = 1.59 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 128, 8): 1.4844719295 sec, performance = 11.57 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 256, 8): 1.347527482 sec, performance = 12.75 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 4, 16): 10.5560071845 sec, performance = 1.63 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 128, 16): 1.5089737525 sec, performance = 11.39 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 4, 32): 11.3420509875 sec, performance = 1.51 GFLOPS\n",
      "\n",
      "matmul_cache_block (4, 4, 64): 12.603379911 sec, performance = 1.36 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 4, 4): 10.5903772175 sec, performance = 1.62 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 128, 4): 1.28547671 sec, performance = 13.36 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 256, 4): 1.1015709265 sec, performance = 15.6 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 4, 8): 9.8366807425 sec, performance = 1.75 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 128, 8): 1.250830254 sec, performance = 13.73 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 256, 8): 1.125693061 sec, performance = 15.26 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 4, 16): 9.6517647445 sec, performance = 1.78 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 128, 16): 1.276999446 sec, performance = 13.45 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 4, 32): 10.2276264905 sec, performance = 1.68 GFLOPS\n",
      "\n",
      "matmul_cache_block (8, 4, 64): 11.931510546 sec, performance = 1.44 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 4, 4): 10.055941268 sec, performance = 1.71 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 128, 4): 1.181379257 sec, performance = 14.54 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 4, 8): 9.5484632005 sec, performance = 1.8 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 128, 8): 1.176709491 sec, performance = 14.6 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 4, 16): 9.4161608385 sec, performance = 1.82 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 128, 16): 1.204631887 sec, performance = 14.26 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 4, 32): 9.968803851 sec, performance = 1.72 GFLOPS\n",
      "\n",
      "matmul_cache_block (16, 4, 64): 11.783800849 sec, performance = 1.46 GFLOPS\n",
      "\n",
      "matmul_cache_block (32, 4, 4): 10.2736603835 sec, performance = 1.67 GFLOPS\n",
      "\n",
      "matmul_cache_block (32, 4, 8): 9.8639358505 sec, performance = 1.74 GFLOPS\n",
      "\n",
      "matmul_cache_block (32, 4, 16): 9.4774916785 sec, performance = 1.81 GFLOPS\n",
      "\n",
      "matmul_cache_block (32, 4, 32): 9.8736907935 sec, performance = 1.74 GFLOPS\n",
      "\n",
      "matmul_cache_block (32, 4, 64): 11.8218500585 sec, performance = 1.45 GFLOPS\n",
      "\n",
      "matmul_cache_block (64, 4, 4): 11.3533783615 sec, performance = 1.51 GFLOPS\n",
      "\n",
      "matmul_cache_block (64, 4, 8): 10.2010834895 sec, performance = 1.68 GFLOPS\n",
      "\n",
      "matmul_cache_block (64, 4, 16): 9.699407276 sec, performance = 1.77 GFLOPS\n",
      "\n",
      "matmul_cache_block (64, 4, 32): 9.973042778 sec, performance = 1.72 GFLOPS\n",
      "\n",
      "matmul_cache_block (64, 4, 64): 11.66506122 sec, performance = 1.47 GFLOPS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"Varying block sizes:\")\n",
    "L1 = cachesize()[1]\n",
    "for cbs in (4, 8, 16, 32, 64), kbs in (4, 8, 16, 32, 64), rbs in (4, 128, 256, 512)\n",
    "    if rbs * kbs + rbs * cbs > L1 / 8\n",
    "        # A block and C block don't fit into L1 cache together\n",
    "        continue\n",
    "    end\n",
    "    t_cache_block = @belapsed matmul_cache_blocking!($C, $A, $B; col_blksize=$cbs, row_blksize=$rbs, k_blksize=$kbs) samples = 1 evals = 2\n",
    "    println(\"matmul_cache_block ($cbs, $rbs, $kbs): \", t_cache_block, \" sec, performance = \", round(2.0e-9 * N^3 / t_cache_block, digits=2), \" GFLOPS\\n\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (1 thread) 1.10.0",
   "language": "julia",
   "name": "julia-_1-thread_-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
