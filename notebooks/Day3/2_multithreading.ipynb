{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are threads?\n",
    "Threads are **execution units within a process** that can run simultaneously. While processes are separate, threads run in a **shared memory** space (heap).\n",
    "\n",
    "<!-- <img src=\"./imgs/what-are-threads.png\" width=500px> -->\n",
    "\n",
    "<br>\n",
    "<img src=\"imgs/stack_heap_threads.svg\" width=450px>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Julia with multiple threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia starts with a single *user thread*. We must tell it explicitly to start multiple user threads. There are two ways to do this:\n",
    "\n",
    "* Environment variable: `JULIA_NUM_THREADS=4`\n",
    "* Command line argument: `julia -t 4`\n",
    "\n",
    "**PC2 Jupyter Hub**\n",
    "\n",
    "- Select a kernel with e.g. **8 threads**:\n",
    "\n",
    "<img src=\"imgs/kernels.png\" width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is currently not (easily) possible to change the number of threads at runtime!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can readily check how many threads we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User threads vs default threads\n",
    "\n",
    "Technically, the Julia process is also spawning multiple threads already in \"single-threaded\" mode, like\n",
    "* a thread for unix signal listening\n",
    "* multiple OpenBLAS threads for BLAS/LAPACK operations\n",
    "* GC threads\n",
    "\n",
    "We call the threads that we can actually run computations on *user threads* or *Julia threads*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "BLAS.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are my threads running?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noctua 2 compute node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ThreadPinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threadinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lstopo_no_graphics`\n",
    "\n",
    "<img src=\"imgs/lstopo_noctua2.svg\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### \"Hyperthreading\" (not active on Noctua 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"imgs/threadinfo.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-based multithreading\n",
    "\n",
    "In traditional HPC, one typically cares about threads directly. Using e.g. OpenMP, one essentially tells each thread what to do.\n",
    "\n",
    "Conceptually, Julia takes a different approach and implements **task-based** multithreading. In this paradigm, a task - e.g. a computational piece of a code - is marked for **parallel** execution on **any** of the available Julia threads. Julia's **dynamic scheduler** will automatically put the task on one of the threads and trigger the execution of the task on said thread.\n",
    "\n",
    "<br>\n",
    "<!-- <img src=\"imgs/task-based-parallelism.png\" width=768px> -->\n",
    "<img src=\"imgs/tasks_threads_cores.svg\" width=650px>\n",
    "</br>\n",
    "\n",
    "Generally speaking, the user should **think about tasks and not threads**.\n",
    "* The scheduler is controlling on which thread a task will eventually run.\n",
    "* It might even dynamically [migrate tasks](https://docs.julialang.org/en/v1/manual/multi-threading/#man-task-migration) between threads.\n",
    "\n",
    "**Advantages:**\n",
    "* high-level abstraction\n",
    "* nestability / composability (especially important for libraries)\n",
    "\n",
    "**Disadvantages:**\n",
    "* scheduling overhead\n",
    "* uncertain and potentially suboptimal task → thread assignment\n",
    "  * **can get in the way when performance engineering** because\n",
    "    * scheduler has limited information (e.g. about the system topology)\n",
    "    * profiling tools often don't know anything about tasks but monitor threads (or even CPU-cores) instead (e.g. LIKWID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for commands to finish (\"**blocking**\") and runs everything sequentially.\n",
    "\n",
    "**Tasks** are a feature that allows (parts of) computations to be scheduled (suspended and resumed) in a flexible manner to implement **concurrency** and **parallelism**.\n",
    "\n",
    "* Concurrency\n",
    "    * Dealing with lots of things *in a time period* (\"multi-tasking\").\n",
    "    * Can be used on a single thread.\n",
    "* Parallelism\n",
    "    * Doing lots of things *at the same instant*.\n",
    "    * Needs multiple threads (or processes).\n",
    "\n",
    "Example (concurrency): **asynchronous I/O** like\n",
    "  * **multiple user input** (Why not already process some of the input?)\n",
    "  * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " \n",
    "Example (parallelism): **multithreading, distributed computing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawning parallel tasks: `Threads.@spawn`\n",
    "`Threads.@spawn` spawns a task to be run on any Julia thread. Specifically, it creates a `Task` and schedules it for execution on an available Julia thread (we don't control which one!).\n",
    "\n",
    "Note that `Threads.@spawn` is **asynchronous** and **non-blocking**, that is, it doesn't wait for the task to actually run but immediately returns a `Task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Base.Threads # afterwards we can just write @spawn instead of Threads.@spawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@spawn 3+3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fetch the result of a task with `fetch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = @spawn 3+3\n",
    "fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `@spawn` returns right away, `fetch` is **blocking** as it has to wait for the task to actually finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@time t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the macro `@sync` to synchronize all encompassed asynchronous operations (`@spawn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@time @sync t = @spawn begin\n",
    "    sleep(3)\n",
    "    return 3+3\n",
    "end\n",
    "@time fetch(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreaded `map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`tmap`: *threaded map*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function tmap(fn, itr)\n",
    "    tasks = map(i -> @spawn(fn(i)), itr)  # for each i ∈ itr, spawn a task to compute fn(i)\n",
    "    return fetch.(tasks)                  # fetch and return all the results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = [rand(200,200) for i in 1:8];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**performance issue**:\n",
    "\n",
    "* Using Julia multithreading + BLAS multithreading\n",
    "    - CPU cores may be *overscribed*, e.g. 256 total threads on 128 CPU cores! (red bars in `htop`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use BLAS, it is important to carefully consider and configure the [interplay between Julia threads and BLAS threads](https://carstenbauer.github.io/ThreadPinning.jl/stable/explanations/blas/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BLAS.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime tmap($svdvals, $M) samples=10 evals=3;\n",
    "@btime map($svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: multithreading for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ThreadPinning: taskid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@sync for i in 1:2*nthreads()\n",
    "    @spawn println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Splits up the iteration space into `nthreads()` contiguous chunks**\n",
    "* Creates a task for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creates nthreads() many tasks\n",
    "\n",
    "@threads for i in 1:2*nthreads()\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load-balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are many tasks (e.g. many more than available threads), Julia's scheduler balances the load of these tasks among threads. (**non-uniform workloads**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function compute_nonuniform_spawn!(a, workloads = [Int[] for _ in 1:nthreads()])\n",
    "    @sync for i in 1:length(a)\n",
    "        Threads.@spawn begin\n",
    "            a[i] = sum(abs2, rand() for j in 1:(2^14*i))   # workload proportional to i\n",
    "            push!(workloads[threadid()], i)                # (poor-man's) bookkeeping\n",
    "        end\n",
    "    end\n",
    "    return workloads\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = zeros(nthreads()*10)\n",
    "workloads = compute_nonuniform_spawn!(a)\n",
    "\n",
    "# plotting\n",
    "thread_workloads = zeros(Int, nthreads(), maximum(length, workloads))\n",
    "for th in eachindex(workloads)\n",
    "    for (i, w) in enumerate(workloads[th])\n",
    "        thread_workloads[th, i] = w\n",
    "    end\n",
    "end\n",
    "b = groupedbar(thread_workloads, xlab=\"threadid\", ylab=\"workload\", title=\"@spawn\", legend=false, bar_position=:stack)\n",
    "# b = bar(sum.(workloads), xlab=\"threadid\", ylab=\"workload\", title=\"Workload (@spawn)\", legend=false, color=:green)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No load-balancing with `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@threads` doesn't give load-balancing because when it **divides the iteration interval into `nthreads()` tasks** there is no flexibility left to give a thread more than a single task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function compute_nonuniform_threads!(a, workloads = [Dict() for _ in 1:nthreads()])\n",
    "    @threads for i in 1:length(a)\n",
    "        a[i] = sum(abs2, rand() for j in 1:(2^14*i)) # workload proportional to i\n",
    "\n",
    "        # poor-man's bookkeeping\n",
    "        d = workloads[threadid()]\n",
    "        d[taskid()] = get!(d, taskid(), 0) + i\n",
    "    end\n",
    "    return workloads\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = zeros(nthreads()*10)\n",
    "workloads = compute_nonuniform_threads!(a)\n",
    "\n",
    "# plotting\n",
    "@assert length(workloads) == nthreads()\n",
    "b = bar([only(values(w)) for w in workloads], xlab=\"threadid\", ylab=\"workload\", title=\"@threads\", legend=false)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* There will likely be a scheduling option for `@threads` that implements load-balancing in the future (see e.g. https://github.com/JuliaLang/julia/pull/52096)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nestability / Composability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Recursive Fibonacci series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F(n) = F(n-1) + F(n-2), \\qquad F(1) = F(2) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nest `@spawn` calls freely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function fib(n)\n",
    "    n < 2 && return n\n",
    "    t = @spawn fib(n-2)\n",
    "    return fib(n-1) + fetch(t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fib(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: Algorithmically, this is a highly inefficient implementation of the Fibonacci series, of course!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multithreading: Things to be aware of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructive example: parallel summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = rand(1_000_000 * Threads.nthreads());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function sum_threads_naive(data)\n",
    "    s = zero(eltype(data))\n",
    "    @threads for x in eachindex(data)\n",
    "        s += x\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@show sum(data);\n",
    "@show sum_threads_naive(data);\n",
    "@show sum_threads_naive(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong** result! Even worse, it's **non-deterministic** and different every time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [race condition](https://en.wikipedia.org/wiki/Race_condition) which typically appear when multiple tasks are modifying a shared value simultaneously.\n",
    "\n",
    "→ **Don't modify shared \"global\" state!**\n",
    "\n",
    "Sometimes things can be more subtle. Examples: random number generation, `Dict`. Note that not all of Julia and its packages in the ecosystem are thread-safe! In general, it is safer to assume that they're not unless documented/proven otherwise. (`rand()` is thread-safe, `Dict` isn't!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thread-focused partial sums (unsafe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy:\n",
    "* One accumulator variable per thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be inclined to write something similar to the following (intentionally written in a slightly more verbose form):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function sum_threads_unsafe(data)\n",
    "    psums = zeros(eltype(data), nthreads())\n",
    "    @threads for i in eachindex(data)\n",
    "        current_sum = psums[threadid()] # read\n",
    "        new_sum = current_sum + data[i] # \"work\"\n",
    "        psums[threadid()] = new_sum     # write\n",
    "    end\n",
    "    return sum(psums)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such an approach is generally **unsafe** because Julia's scheduler may **migrate tasks between threads**!\n",
    "  * For example, a task might start on thread 1, is then paused (say, after \"work\") and migrated to thread 3, where it finishes execution.\n",
    "  * → The output of `threadid()` might change within a task! To be safe, [don't use `threadid()`](https://julialang.org/blog/2023/07/PSA-dont-use-threadid/) at all!\n",
    "  \n",
    "It also goes against the idea of task-based multithreading, as we're **thinking about threads rather than tasks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that, in spite of the comments above, the `threadid()` pattern will often still work correctly. This is because as of Julia 1.10 task migrations are very rare. Importantly, **you can't rely on it though!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk-focused partial sums (safe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy:\n",
    "* Divide the data (indices) into **chunks** and use **one accumulator per chunk**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package [ChunkSplitters.jl](https://github.com/m3g/ChunkSplitters.jl) is helpful for chunking (`Iterators.partition` is a built-in alternative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ChunkSplitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collect(chunks(data; n=nthreads())) # number of chunks chosen as nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function sum_threads_chunks(data; nchunks=nthreads())\n",
    "    psums = zeros(eltype(data), nchunks)\n",
    "    @threads for (c, idcs) in enumerate(chunks(data; n=nchunks))\n",
    "        for i in idcs\n",
    "            psums[c] += data[i]\n",
    "        end\n",
    "    end\n",
    "    return sum(psums)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_threads_chunks(data) ≈ sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime sum($data);\n",
    "@btime sum_threads_chunks($data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safe, but (horribly) slow?! Why?\n",
    "\n",
    "* manual loop doesn't SIMD (need to add manual `@simd` + `@inbounds`)\n",
    "* But more importantly: **false sharing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance issue: [False sharing](https://en.wikipedia.org/wiki/False_sharing)\n",
    "\n",
    "Why does `sum_threads_chunks` above have bad performance? Although argubaly subtle, this is because different tasks mutate shared data (`psums`) in parallel. There is no *logical* sharing: Tasks access different slots of `psums` and there is no data race. However, CPU cores work on the basis of **cache lines** instead of single elements leading to *implicit* sharing of cache lines.\n",
    "\n",
    "**Despite its subtlety, false sharing can lead to dramatic slowdown!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using CpuId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cachelinesize() ÷ sizeof(Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/false_sharing.svg\" width=850px>\n",
    "\n",
    "Different tasks modify the same cache line\n",
    "* need for synchronization to ensure cache coherency\n",
    "* performance decreases (dramatically).\n",
    "\n",
    "**The less you modify non-local state, the better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk-focused task-local partial sums (good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function sum_threads_chunks_local(data; nchunks=nthreads())\n",
    "    psums = zeros(eltype(data), nchunks)\n",
    "    @threads for (c, idcs) in enumerate(chunks(data; n=nchunks))\n",
    "        local s = zero(eltype(data))\n",
    "        @simd for i in idcs\n",
    "            @inbounds s += data[i]\n",
    "        end\n",
    "        psums[c] = s\n",
    "    end\n",
    "    return sum(psums)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* each task/iteration computes a local sum (`s`) independently\n",
    "* no *frequent* non-local mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(data) ≈ sum_threads_chunks_local(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime sum($data);\n",
    "@btime sum_threads_chunks_local($data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-focused version (even better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key questions for task-based parallelisation:**\n",
    "* How to divide the computation into seperate **tasks**?\n",
    "* How many **tasks** should we create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conceptually, this is just `tmap(mysum, chunks)`\n",
    "\n",
    "function sum_map_spawn(data; nchunks=nthreads())\n",
    "    ts = map(chunks(data, n=nchunks)) do idcs\n",
    "        @spawn @views sum(data[idcs])\n",
    "    end\n",
    "    return sum(fetch.(ts))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Loop analogue (click to unfold)</summary>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "```julia\n",
    "function sum_loop_spawn(data; nchunks=nthreads())\n",
    "    ts = Vector{Task}(undef, nchunks)\n",
    "    for (c, idcs) in enumerate(chunks(data; n=nchunks))\n",
    "        ts[c] = @spawn @views sum(data[idcs])\n",
    "    end\n",
    "    return sum(fetch.(ts))\n",
    "end\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This version is task-focused → We're **explicitly** spawning one task per chunk.\n",
    "* In this form, we don't need a manual pre-allocation (it is hidden in the map operation)\n",
    "  * → no explicit indexing necessary (and thus no `enumerate` around `chunks`).\n",
    "  * We have automatically circumvented the false sharing performance issue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_map_spawn(data) ≈ sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime sum_map_spawn($data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still interesting performance improvements possible. However, this is beyond the scope of the course. 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Opt out of dynamic scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For \"traditional HPC\", where you tell each thread what to do, you might in some cases want/need a **guaranteed task-thread mapping**. This is possible to achieve with the following tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@spawnat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can opt-out of task migration and **spawn *sticky* tasks on specific threads**. \n",
    "\n",
    "Base Julia doesn't have a built-in macro for this but many packages, including [ThreadPinning.jl](https://github.com/carstenbauer/ThreadPinning.jl), provide a variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ThreadPinning: @spawnat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@spawnat 4 println(\"Task \", taskid(), \" is running on thread \", threadid());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `@threads :static`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `@threads` there is the `:static` scheduling option to opt-out of Julia's dynamic scheduling.\n",
    "\n",
    "Syntax: `@threads :static for ...`\n",
    "\n",
    " * **statically** maps tasks/chunks to threads, specifically: task 1 → thread 1, task 2 → thread 2, and so on.\n",
    "   * no task migration, i.e. **fixed task-thread mapping** 👍\n",
    "   * only little overhead 👍\n",
    "   * not composable / nestable 👎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@threads :dynamic for i in 1:2*nthreads() # :dynamic is the default\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid());\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@threads :static for i in 1:2*nthreads()\n",
    "    println(\"Task \", taskid(), \" is running iteration \", i, \" on thread \", threadid());\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `@threads :static`, every thread handles precisely two iterations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Additional comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tools for multi-threading\n",
    "\n",
    "* [OhMyThreads.jl](https://github.com/JuliaFolds2/OhMyThreads.jl): Simple tools for basic multithreading.\n",
    "* [ThreadsX.jl](https://github.com/JuliaFolds2/ThreadsX.jl): Parallelized Base functions\n",
    "* [Tullio.jl](https://github.com/mcabbott/Tullio.jl): Tullio is a very flexible einsum macro ([Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation))\n",
    "* [(LoopVectorization.jl)](https://github.com/JuliaSIMD/LoopVectorization.jl): Macro(s) for vectorizing loops.\n",
    "* [(FLoops.jl)](https://github.com/JuliaFolds/FLoops.jl): Fast sequential, threaded, and distributed for-loops for Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [OhMyThreads.jl](https://github.com/JuliaFolds2/OhMyThreads.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using OhMyThreads: treduce, tmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treduce(+, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@btime treduce($+, $data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmap(sin, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinning Julia threads to CPU threads/cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compute node has a complex topology (two sockets, multiple memory channels/domains). Placing the Julia threads systematically on CPU-threads matters for\n",
    "\n",
    "* the computation performance of your Julia codes\n",
    "* fluctuations/noises in benchmarks\n",
    "* hardware-level performance monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about external tools like `numactl`, `taskset`, etc.? Doesn't work reliably because they often [can't distinguish](https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/5) between Julia threads and other internal threads.\n",
    "\n",
    "**Options:**\n",
    "\n",
    "* `JULIA_EXCLUSIVE=1`\n",
    "* [ThreadPinning.jl](https://github.com/carstenbauer/ThreadPinning.jl)\n",
    "\n",
    "#### ThreadPinning.jl\n",
    "\n",
    "<!-- <br>\n",
    "<img src=\"imgs/threadpinning_pinthreads.svg\" width=600px>\n",
    "</br> -->\n",
    "\n",
    "`pinthreads(strategy)`\n",
    "* `:cputhreads` pin to CPU threads (incl. \"hypterthreads\") one after another\n",
    "* `:cores:` pin to CPU cores one after another\n",
    "* `:numa:` alternate between NUMA domains so, e.g., 0, 16, 32, 48, 64, .... (if a NUMA domain has 16 cores)\n",
    "* `:sockets:` alternate between sockets so, e.g., 0, 64, 1, 65, 2, 66, .... (if a socket has 64 cores)\n",
    "* `:affinitymask`: pin according to an external affinity mask (e.g. set by SLURM)\n",
    "\n",
    "(More? See my short talk at JuliaCon2023 @ MIT: https://youtu.be/6Whc9XtlCC0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinthreads(:affinitymask)\n",
    "threadinfo(; slurm=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garbage collection\n",
    "\n",
    "If it gets triggered, it stops the world (all threads) for clearing up memory.\n",
    "\n",
    "Hence, when using multithreading, it is even more important to **avoid heap allocations!**\n",
    "\n",
    "(If you can't avoid allocations, consider using multiprocessing instead.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic operations and locks\n",
    "\n",
    "See [Atomic Operations](https://docs.julialang.org/en/v1/manual/multi-threading/#Atomic-Operations) and/or [Data-race freedom](https://docs.julialang.org/en/v1/manual/multi-threading/#Data-race-freedom) in the Julia doc for more information. In general, one should avoid using them as much as possible since they actually limit the parallelization by serialized executions (especially if you don't know what you're doing). That said, locks can be an effective way to use a data structures that themselves aren't thread safe, e.g. `Dict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll explore the effect of thread pinning on performance in more detail later → **daxpy_cpu exercise**"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.10.0",
   "language": "julia",
   "name": "julia-_8-threads_-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
